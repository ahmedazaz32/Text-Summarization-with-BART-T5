{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedazaz32/Text-Summarization-with-BART-T5/blob/main/Text_summarization_with_BART_%26_T5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qiu5ApLOxeG"
      },
      "source": [
        "# Summarise classical books with state-of-the-art machine learning models\n",
        "BART and T5 are state-of-the-art machine learning models developed by [Lewis et al. 2019 (Facebook Research)](https://arxiv.org/abs/1910.13461) and [Raffel et al. 2019 (Google Research)](https://arxiv.org/abs/1910.10683). They have been trained to summarize text and are made available for easy use by [@HuggingFace](https://twitter.com/huggingface)'s [Transformers library](https://huggingface.co/transformers/). This notebook shows how to summarise history's most influential books like the Communist Manifesto or Orwell's 1984 in a few lines of code in a few minutes with these two models. You can copy the notebook, run and change it yourself and compare the two models. Notebook by [@MoritzLaurer](https://twitter.com/MoritzLaurer)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4DSFAVExnOS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "701fb33a-628f-4a3b-eaeb-9f8739aec10b"
      },
      "source": [
        "## installation\n",
        "# see https://twitter.com/huggingface/status/1242512382800400384\n",
        "# details https://github.com/huggingface/transformers/releases/tag/v2.6.0\n",
        "!pip install transformers --upgrade"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed transformers-4.36.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYsqgk9nxUPc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "9579c399-29d4-4a4c-de12-820105913dcd"
      },
      "source": [
        "from transformers import pipeline\n",
        "import requests\n",
        "import pprint\n",
        "import time\n",
        "pp = pprint.PrettyPrinter(indent=14)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1381\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mquestion_answering\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuestionAnsweringArgumentHandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQuestionAnsweringPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtable_question_answering\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTableQuestionAnsweringArgumentHandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTableQuestionAnsweringPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtext2text_generation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummarizationPipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mText2TextGenerationPipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTranslationPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/table_question_answering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_probability\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_probability/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubstrates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m# from tensorflow_probability.google import staging  # DisableOnExport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_probability/substrates/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mall_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlazy_loader\u001b[0m  \u001b[0;31m# pylint: disable=g-direct-tensorflow-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mpkg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_maybe_nonlazy_load\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Forces loading the package from its lazy loader.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/internal/lazy_loader.py\u001b[0m in \u001b[0;36m__dir__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/internal/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_first_access\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_first_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_first_access\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_probability/python/__init__.py\u001b[0m in \u001b[0;36m_validate_tf_environment\u001b[0;34m(package)\u001b[0m\n\u001b[1;32m     58\u001b[0m       distutils.version.LooseVersion(required_tensorflow_version)):\n\u001b[0;32m---> 59\u001b[0;31m     raise ImportError(\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;34m'This version of TensorFlow Probability requires TensorFlow '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: This version of TensorFlow Probability requires TensorFlow version >= 2.14; Detected an installation of version 2.12.0. Please upgrade TensorFlow to proceed.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7a662ad412c6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrettyPrinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1370\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   1385\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0;34mf\" traceback):\\n{e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\nThis version of TensorFlow Probability requires TensorFlow version >= 2.14; Detected an installation of version 2.12.0. Please upgrade TensorFlow to proceed."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWzDuuEmICBM"
      },
      "source": [
        "## documentation for summarizer: https://huggingface.co/transformers/main_classes/pipelines.html#summarizationpipeline\n",
        "# summarize with BART\n",
        "summarizer_bart = pipeline(task='summarization', model=\"bart-large-cnn\")\n",
        "# summarize with T5\n",
        "summarizer_t5 = pipeline(task='summarization', model=\"t5-large\") # options: ‘t5-small’, ‘t5-base’, ‘t5-large’, ‘t5-3b’, ‘t5-11b’\n",
        "#for T5 you can chose the size of the model. Everything above t5-base is very slow, even on GPU or TPU."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB-rU6H8D2Pu"
      },
      "source": [
        "## 1. Karl Marx, Friedrich Engels - Manifesto of the Communist Party"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlhrWHkex4An"
      },
      "source": [
        "## download book\n",
        "book_raw = requests.get(\"http://www.gutenberg.org/cache/epub/61/pg61.txt\")\n",
        "communist_manifesto = book_raw.text\n",
        "# cleaning\n",
        "delimiter = \"[From the English edition of 1888, edited by Friedrich Engels]\"\n",
        "communist_manifesto_cl = communist_manifesto.split(delimiter, 1)[1]\n",
        "delimiter2 = \"WORKING MEN OF ALL COUNTRIES, UNITE!\"\n",
        "communist_manifesto_cl =  communist_manifesto_cl.split(delimiter2, 1)[0] + delimiter2\n",
        "#print(communist_manifesto_cl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq-STYpSitT6"
      },
      "source": [
        "#### 1.1 - BART model, machine-generated summary  - Communist Manifesto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a94yDQC2zxT5"
      },
      "source": [
        "## summarize book with BART model\n",
        "t0 = time.time() # timer\n",
        "summary_manifesto_bart = summarizer_bart(communist_manifesto_cl, min_length=150, max_length=500) # change min_ and max_length for different output\n",
        "print(\"Summarization took \" + str(round((time.time() - t0) / 60, 2)) + \" minutes.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99JXDTe_zpVN"
      },
      "source": [
        "pp.pprint(summary_manifesto_bart[0]['summary_text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR8XdhOgkJzw"
      },
      "source": [
        "#### 1.2 - T5 model, machine-generated summary - Communist Manifesto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaZIDnEikEc-"
      },
      "source": [
        "## summarize book with T5 model\n",
        "t0 = time.time() # timer\n",
        "summary_manifesto_t5 = summarizer_t5(communist_manifesto_cl, min_length=150, max_length=500) # change min_ and max_length for different output\n",
        "print(\"Summarization took \" + str(round((time.time() - t0) / 60, 2)) + \" minutes.\") # timer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoopAFnE1EhA"
      },
      "source": [
        "pp.pprint(summary_manifesto_t5[0]['summary_text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf_ptyCMCQDF"
      },
      "source": [
        "## 2. George Orwell - 1984"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzQJQCkACOeH"
      },
      "source": [
        "## download book\n",
        "book_raw = requests.get(\"http://gutenberg.net.au/ebooks01/0100021.txt\")\n",
        "orwell_1984 = book_raw.text\n",
        "# cleaning\n",
        "delimiter = 'PART ONE'\n",
        "orwell_1984_cl = delimiter + orwell_1984.split(delimiter, 1)[1]\n",
        "delimiter2 = \"THE END\"\n",
        "orwell_1984_cl = orwell_1984_cl.split(delimiter2, 1)[0] + delimiter2\n",
        "#print(orwell_1984_cl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOCnkYB9kphf"
      },
      "source": [
        "#### 2.1 - BART model, machine-generated summary  - Orwell 1984"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFhP42aXCa-B"
      },
      "source": [
        "## summarize book with BART model\n",
        "t0 = time.time() # timer\n",
        "summary_orwell_bart = summarizer_bart(orwell_1984_cl, min_length=150, max_length=500) # change min_ and max_length for different output\n",
        "print(\"Summarization took \" + str(round((time.time() - t0) / 60, 2)) + \" minutes.\") # timer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM-8vl_tkp_w"
      },
      "source": [
        "pp.pprint(summary_orwell_bart[0]['summary_text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX03J_1JmMRo"
      },
      "source": [
        "#### 2.2 - T5 model, machine-generated summary - Orwell 1984\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2iLwgiGmMxO"
      },
      "source": [
        "## summarize book with T5 model\n",
        "t0 = time.time() # timer\n",
        "summary_orwell_t5 = summarizer_t5(orwell_1984_cl, min_length=150, max_length=500) # change min_ and max_length for different output\n",
        "print(\"Summarization took \" + str(round((time.time() - t0) / 60, 2)) + \" minutes.\") # timer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr3aQAu7mNEn"
      },
      "source": [
        "pp.pprint(summary_orwell_t5[0]['summary_text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFlKWQAUDfe3"
      },
      "source": [
        "## 3. Charles Darwin - The Origin of Species by Means of Natural Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHeu2zJp0xBi"
      },
      "source": [
        "## download book\n",
        "book_raw = requests.get(\"http://www.gutenberg.org/cache/epub/2009/pg2009.txt\")\n",
        "darwin_origin_of_species = book_raw.text\n",
        "# cleaning\n",
        "delimiter = 'INTRODUCTION.'\n",
        "darwin_origin_of_species_cl = \"ORIGIN OF SPECIES.\" + delimiter + darwin_origin_of_species.split(delimiter, 1)[1]\n",
        "delimiter2 = \"GLOSSARY OF THE PRINCIPAL SCIENTIFIC TERMS USED IN THE PRESENT VOLUME.\"\n",
        "darwin_origin_of_species_cl =  darwin_origin_of_species_cl.split(delimiter2, 1)[0]\n",
        "print(darwin_origin_of_species_cl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciA_9N8jkJ2C"
      },
      "source": [
        "#### 3.1 - BART model, machine-generated summary - Darwin, Origin of Species"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLnfRQqS1QFk"
      },
      "source": [
        "## summarize book with BART model\n",
        "t0 = time.time() # timer\n",
        "summary_darwin_bart = summarizer_bart(darwin_origin_of_species_cl, min_length=150, max_length=500) # change min_ and max_length for different output\n",
        "print(\"Summarization took \" + str(round((time.time() - t0) / 60, 2)) + \" minutes.\") # timer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_usRy_ErkJX3"
      },
      "source": [
        "pp.pprint(summary_darwin_bart[0]['summary_text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doK7RPRzmyG-"
      },
      "source": [
        "#### 3.2 - T5 model, machine-generated summary  - Darwin, Origin of Species"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXqy0eNAmyl8"
      },
      "source": [
        "## summarize book with T5 model\n",
        "t0 = time.time() # timer\n",
        "summary_darwin_t5 = summarizer_t5(darwin_origin_of_species_cl, min_length=150, max_length=500) # change min_ and max_length for different output\n",
        "print(\"Summarization took \" + str(round((time.time() - t0) / 60, 2)) + \" minutes.\") # timer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0ft2KMHmzSv"
      },
      "source": [
        "pp.pprint(summary_darwin_t5[0]['summary_text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuST_wCqC-vE"
      },
      "source": [
        "## 4. Mary Wollstonecraft - A Vindication of the Rights of Woman"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57Ff6suE72O3"
      },
      "source": [
        "## download book\n",
        "book_raw = requests.get(\"http://www.gutenberg.org/cache/epub/3420/pg3420.txt\")\n",
        "rights_woman = book_raw.text\n",
        "# cleaning\n",
        "delimiter = 'A VINDICATION OF THE RIGHTS OF WOMAN,'\n",
        "rights_woman_cl = delimiter + rights_woman.split(delimiter, 1)[1]\n",
        "#print(rights_woman_cl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoB0Jrp0kYRi"
      },
      "source": [
        "#### 4.1 - BART model, machine-generated summary - Rights of Woman"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NPcSlIY8JMo"
      },
      "source": [
        "## summarize book\n",
        "t0 = time.time() # timer\n",
        "summary_rights_woman_bart = summarizer_bart(rights_woman_cl, min_length=150, max_length=500) # change min_ and max_length for different output\n",
        "print(\"Summarization took \" + str(round((time.time() - t0) / 60, 2)) + \" minutes.\") # timer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_BN_wuRkYBl"
      },
      "source": [
        "pp.pprint(summary_rights_woman_bart[0]['summary_text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9DMMY3dnQ5P"
      },
      "source": [
        "#### 4.2 - T5 model, machine-generated summary - Rights of Woman"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8GzBp-1nRcS"
      },
      "source": [
        "## summarize book\n",
        "t0 = time.time() # timer\n",
        "summary_rights_woman_t5 = summarizer_t5(rights_woman_cl, min_length=150, max_length=500) # change min_ and max_length for different output\n",
        "print(\"Summarization took \" + str(round((time.time() - t0) / 60, 2)) + \" minutes.\") # timer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjxc_lv5nRyN"
      },
      "source": [
        "pp.pprint(summary_rights_woman_t5[0]['summary_text'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}